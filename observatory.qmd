# Open Music Observatory: Building a Shared Music Data Space {#sec-observatory}

::: callout-note
#### Open Music Observatory {.unnumbered}

Our ambition with the development of the **Open Music Observatory** is to provide the technological basis and a practical roadmap for creating a European Music Observatory in a bottom-up, decentralised way. Instead of waiting for a grand, central agreement, any data owners or collectors who satisfy quality and cooperation rules can add their data. Once the Observatory reaches sufficient maturity, its long-term institutional form can be decided.

The Open Music Observatory is a cornerstone task of the OpenMusE project (running until 31 December 2025), delivering data collection, processing, dissemination, and innovative services. It is a digital service provider for the music industry, aligned with the *European Interoperability Framework*, and introduces a unique governance model that adapts best practices from the EU and other sectors.

**Transparency note:** Following the principles of **Open Policy Analysis**, we have made all key deliverables (including versions 0.99, 1.01, and 1.1 of the *Open Music Observatory* document) publicly accessible to foster broad stakeholder engagement and to provide a clear audit trail. These versions are available at <https://zenodo.org/records/11564114>, while version 1.0 remains internal and was shared only with OpenMusE evaluators. Minor edits, as well as access to the standardised folders, figures, and bibliographies, can be found at <https://github.com/dataobservatory-eu/open-music-observatory>.

**Citation note:** If you refer to the specification of the *Open Music Observatory* in correspondence, publications, or blog posts, please cite the latest **versioned DOI** available on Zenodo and, if applicable, include the date of access when referring to material on our GitHub repository.[^observatory-1]
:::

[^observatory-1]: Always use the latest versioned DOI when citing this *Open Music Observatory* technical report, available via Zenodo. If you rely on supporting material hosted in the GitHub repository, please add the date of access in your reference.

## Executive summary

::: callout-caution
**This will be finalised after consultation**

-   Build a federated data sharing space that lets rights orgs, distributors, platforms, libraries/archives share *just enough* metadata with clear roles, auditability, and lifecycle continuity.

-   Use simple, modular agreements and conformance tests rather than a heavy centralised repository.
:::

The Music Ecosystem 2025 report already emphasised that the music sector should be understood as a distributed ecosystem where value and knowledge are held by many small actors [@music_ecossytem_2025, pp6–7]. This perspective reinforces why centralised repositories fail and why federated observatories, built on cooperation and interoperability, are more realistic.

[![Over the past decade, feasibility studies, national reports, and EU pilot projects have laid the foundation for the Open Music Observatory. The roadmap (2014–2026) shows a gradual build-up: from local experiments, through cross-border collaborations, to a European-wide federation aligned with cultural data spaces and interoperability frameworks. This trajectory underlines the Observatory’s pragmatic, step-by-step approach to scaling music data infrastructure. DOI: \[10.6084/m9.figshare.30073291.v1\](https://doi.org/10.6084/m9.figshare.30073291.v1)](png/OMO/OMO_timeline_20250908.png){fig-align="center"}](https://figshare.com/articles/figure/Timeline_of_the_Open_Music_Observatory_and_European_Music_Data_Initiatives_2014_2026_/30073291/1?file=57754420)

## Discussion

::: callout-caution
**This will be removed consultation** - EMO feasibility on scarcity/fragmentation and the need for regular, comparable data; EU dataspace thinking (EIF, FAIR); *Music Ecosystem 2025* on systemic view. - Industry positions on centralisation vs. federation; CMOs’ reliance on shared infra (e.g., Mint); heritage sector’s openness requirements.
:::

### Why centralisation is a futile model

Calls for a *centralised European database* of music often reappear in policy debates, but in practice such proposals are neither realistic nor aligned with current EU strategies. Centralisation assumes that highly diverse data sources can be harmonised within a single repository. In an ecosystem where knowledge is held by tens of thousands of micro-enterprises, NGOs, collective management organisations, and heritage institutions — each operating under distinct legal frameworks — this assumption is untenable.

EU infrastructure initiatives have already moved beyond this logic. Since the 2000s, projects such as *Europeana*, the *European Open Science Cloud (EOSC)*, the *European Collaborative Cloud for Cultural Heritage (ECCCH)*, and *DARIAH* have all adopted **federated architectures**, linking distributed collections through shared standards and interoperability frameworks rather than consolidating them into one database. The *Audiovisual Observatory*, established in 1993 as a centralised reporting body, represents an earlier institutional logic that is now being phased out in favour of federation.

The heritage sector, including music heritage, has consistently stressed the need for *open, federated models*. Libraries, archives, and museums use authority files and collaborative platforms (e.g. VIAF, *Wikidata*, Wikibase) to enable interoperability while preserving institutional autonomy. Commercial infrastructures do the same: the ISRC system, managed by IFPI, is inherently decentralised, while CISAC’s *CIS-Net* gives access to rights data without centralising ownership. Even the Mint initiative, launched by CISAC and Armonia Online, shows how shared infrastructure can deliver economies of scale for identifier allocation and metadata management while avoiding dependence on a single repository.[^observatory-2]

[^observatory-2]: On heritage practices, see [@bianchini_beyond_2021, p210] and [@sardo_wikidata_2022, p297], which describe how VIAF, Wikidata, and Wikibase function as authority tools in libraries and archives. On identifiers, the *ISRC Handbook* [@isrc_handbook_2021, p5] explains the decentralised structure of the ISRC system, while CISAC’s *Mint Digital Services* [@cisac_mint_digital_services] illustrates how federated allocation works in practice. Together, these examples show how distributed stewardship and shared standards underpin global metadata infrastructures.

Even official governmental statistics, often seen as centralised, are in reality decentralised. The **ESSnet-Culture** project, coordinated under Eurostat, produced the first comprehensive framework for cultural statistics in 2012, adapted from the UNESCO model, and remains a *“basic reference”* for the field. More broadly, national statistical offices, labour force surveys, and administrative registers each collect partial data, which are harmonised at EU level for comparability. Increasingly, surveys and administrative datasets are complemented by flows from platforms, rights management organisations, and other industry actors. Indicators therefore emerge from **hybrid constellations of public and private data sources**, confirming that decentralisation is a structural feature of European evidence creation.[^observatory-3]

[^observatory-3]: The *ESSnet-Culture* framework [@emo_feasibility_2020, p9] demonstrates how cultural statistics are built on national contributions harmonised at EU level, not on central databases. A Slovak pilot [@antal_slovak-cult-stat-pilot] further illustrates how decentralisation works in practice, integrating public and private sources into coherent cultural indicators.

### Open Data Directive: right without means

The *Open Data Directive* grants a right of reuse for public-sector information and requires that certain “high-value datasets” be made freely available across Europe [@directive_open_data_2019]. This includes cultural heritage institutions such as libraries, museums, and archives. However, the Directive stops short of providing the means to ensure that such data is actually usable.

Studies consistently show that open data often remains more of a promise than a reality. In practice, much open data is poorly documented, lacks common identifiers, and is released in unstandardised formats. While it may be free of charge or available at marginal cost, making it interoperable and trustworthy for cross-border use requires significant additional effort. The burden of curation, harmonisation, and enrichment falls on downstream users, which can be prohibitively expensive for smaller organisations. As the CEDAR project put it, *“Public authorities are only required to make existing data available, not to create new data or improve existing systems. This leads to significant disparities in usability and accessibility”* [@cedar_hvd_2023]. A recent EU-wide usability study adds that *“many open data portals remain difficult to navigate, poorly documented, and inconsistent in their metadata quality, limiting actual reuse”*  [@jachimczyk_open_data_usability_2024].  
These structural weaknesses of open data provision set the stage for the Observatory’s role in providing workflow playbooks and redundancy-free registration, discussed in @sec-observatory-proposals.[^observatory-4]

[^observatory-4]: Early modelling stressed the economic potential of open data but also identified major obstacles in practice: lack of availability, uneven quality, and poor usability [@carrara_creating_2015, p7; @huyer_economic_2020, p14]. Comparative studies show that simply granting a right to reuse rarely produces machine-actionable datasets. In complex domains like music, where attribution depends on precise identifiers, these shortcomings become particularly costly. Cross-sector reviews underline persistent fragmentation: heterogeneous formats and divergent practices across Member States [@buttow_meijer_openness_2024, p12]; variability even in high-value geospatial datasets [@kevic_godi_plus_2023, p3]; and sectoral case studies (e.g. mineral intelligence) repeatedly call for shared profiles beyond legal openness [@simoni_mintell4eu_2021, p5]. Additional evidence shows that preparing legacy administrative data for reuse requires cleansing and enrichment that impose real costs, even when the data are nominally “open” [@eurosdr_nmcabiz_2021, p9; @schnurr_ogd_markets_2021, p14; @nakos_nautical_2022, p6].

### Why voluntary workarounds do not scale {#sec-gdpr-observatory}

The Slovak pilot shows that voluntary workarounds for attribution under GDPR are possible (see @sec-gdpr-curation), but they do not scale. Even with strong communication and opt-in procedures, fewer than 1.3% of authors responded. Every new dataset requires fresh balancing tests, repeated notifications, and continued exposure to legal risk.

For observatories and data spaces, this is untenable. Interoperability requires clarity and legal certainty across borders and institutions. Without guidance from a Data Protection Authority or the European Commission, every national or sectoral initiative risks being challenged. The result is paralysis: public infrastructures cannot fully attribute works, and private actors refrain from sharing metadata for fear of liability.

In effect, Europe’s music data infrastructures remain locked in uncertainty — unable to guarantee attribution, diversity monitoring, or local content compliance. This makes a purely local or voluntary approach insufficient. The solution must be systemic: a **federated data sharing space**, supported by common specifications and clear governance frameworks, so that attribution and interoperability can scale. How such systemic solutions can be embedded into the Observatory’s conformance and legal levers is developed in @sec-observatory-proposals. These unresolved attribution issues ultimately undermine not only observatories but also AI fairness and governance (see @sec-gdpr-ai)[^observatory-5]. 

[^observatory-5]: The Slovak pilot demonstrated that even with careful communication and GDPR balancing tests, participation was below 1.3%, showing the practical limits of voluntary attribution workarounds. Without EU-level guidance, every dataset requires fresh legal reasoning, making scale impossible. Comparable findings in other cultural domains underline the risk: voluntary consent-based models tend to collapse under low response rates and high compliance costs. See also discussions of attribution and AI fairness in [@emo_feasibility_2020] and [@music_ecossytem_2025].

### Public infrastructures bypass music’s real data flows

Europe has invested heavily in cultural and research data infrastructures such as *Europeana*, the European Collaborative Cloud for Cultural Heritage (ECCCH), and the European Open Science Cloud (EOSC). Yet these initiatives remain poorly aligned with how music metadata is generated and maintained in practice — mostly by private actors such as labels, distributors, and collective management organisations. Unlike archives, museums, or libraries, where digitisation was largely funded with public money, in music and film the bulk of digitisation has been carried out by industry. Public infrastructures therefore miss the systems where music’s real data flows originate.

The *Europeana Data Model* (EDM) was designed for library holdings and is well suited to printed works, but it cannot capture the attribution needs of recorded music, which must identify at least three groups of rightsholders: authors, producers, and performers.[^observatory-6] The *ECCCH report* likewise overlooked music entirely, focusing instead on monuments, archaeology, textiles, and museums.[^observatory-7] Its first projects — such as **AUTOMATA**, **TEXTaiLES**, **HERITALISE**, and **ECHOES** — developed advanced tools for other heritage assets, but none addressed music directly. Our own attempts to include music datasets in ECHOES’ cascading grants illustrate the problem: proposals were screened out early, despite the clear need for music representation.

[^observatory-6]: The EDM builds on DCTERMS, which works well for printed music but not for recordings. It fails to capture neighbouring rights such as those of producers and performers [@EDM_2017].

[^observatory-7]: *Ex–ante impact assessment on the European Collaborative Cloud for Cultural Heritage* [@eccch_report_2022]. The first ECCCH pilots (AUTOMATA, TEXTaiLES, HERITALISE, ECHOES) focused on archaeology, textiles, and monuments, leaving music out.

Other initiatives show the same bias. The **Polifonia** project created modular ontologies, but it was “blind” to rights management and did not align with ISWC and ISRC identifiers used by industry. As a result, public knowledge graphs and registries do not interoperate smoothly with private-sector identifiers. The result is duplication, costly reconciliation, and under-use of culturally significant catalogues.

EOSC, intended as Europe’s backbone for research data, is also relevant. Its federated model provides long-term preservation and persistent identifiers (via Zenodo and OpenAIRE), and music datasets deposited there already attract visibility. But EOSC has no dedicated workflow for music, and industry uptake remains minimal. As with ECCCH, music is underrepresented and rights-aware curation pathways are absent.[^observatory-8]

[^observatory-8]: EOSC provides federated access and persistence through Zenodo and OpenAIRE, but music workflows remain marginal. On EOSC’s role, see the *European Strategy for Data* [@european_data_strategy_2020].

The **European Interoperability Framework (EIF)** helps explain why these gaps persist. Interoperability depends not only on formats but also on legal, organisational, semantic, and technical alignment. Without shared governance and profiles, public and private systems diverge. The **principle of subsidiarity** adds another layer: stewardship over cultural data is distributed across national and regional authorities, as well as private actors. Centralisation is therefore both impractical and politically illegitimate. The challenge is not whether decentralisation should exist, but how to make decentralised contributions work together.[^observatory-9]  
This challenge directly motivates the Observatory’s bridging role with EOSC, Europeana, and ECCCH, elaborated in @sec-observatory-proposals[^observatory-9].  

[^observatory-9]: The EIF defines layered interoperability (legal, organisational, semantic, technical) [@eif_2017]. The *European Strategy for Data* frames subsidiarity as compatible with federation [@european_data_strategy_2020]. BDVA and the Federation Working Group emphasise that interoperability frameworks are needed to operationalise federation [@bdva_discussion_paper_2023; @federation_wg_position_2023].

### Subsidiarity and infrastructures for scaling music data

The European principle of **subsidiarity** requires that decisions be taken as closely as possible to the citizens they affect. In cultural policy, this means that responsibilities are distributed across multiple levels: in some Member States, culture is managed regionally or provincially; in others, nationally. Beyond public administrations, many important datasets are held by private actors — collective management organisations, platforms, or archives. Any attempt to centralise music data governance would therefore risk losing both legitimacy and local relevance.

Instead, subsidiarity must be built into the design of the Observatory. The **European Interoperability Framework (EIF)** provides a layered model — legal, organisational, semantic, and technical — for reconciling governance across institutions. The **Data Governance Act (DGA)** codifies the same principle: Member States retain stewardship over sensitive datasets, but EU-level standards ensure they can circulate securely and comparably across borders. The **Data Space Support Centre (DSSC)** extends this approach into practice, developing blueprints and building blocks that allow decentralised initiatives to scale. Together, these frameworks show how subsidiarity and federation are not barriers but design principles for data spaces.[^observatory-10]

[^observatory-10]: On subsidiarity and federation: the *Data Governance Act* [@regulation_dga_2022_868] and the *European Strategy for Data* [@european_data_strategy_2020]. On technical frameworks: DSSC’s blueprints [@dssc_blueprint_intro_2025; @dssc_blueprint_interop_2025]. On governance: BDVA [@bdva_discussion_paper_2023] and the Federation Working Group [@federation_wg_position_2023].

At the technical level, **Wikidata and Wikibase** provide a proven backbone for collaborative metadata management. They are already embedded in EU infrastructures such as the official EU Knowledge Graph and in national projects like **MetaBelgica** in Belgium. In Flanders, the performing arts field has gone further: since 2017, *Kunstenpunt* and meemoo have published decades of performing arts data on Wikidata, showing how enrichment happens automatically once data becomes part of a wider ecosystem. These pilots illustrate how subsidiarity and federation can work in practice, with decentralised actors maintaining control of their own data while contributing to a shared framework.[^observatory-11]

[^observatory-11]: On Wikidata/Wikibase in heritage: [@bianchini_beyond_2021; @sardo_wikidata_2022]. On official adoption: EU Knowledge Graph [@diefenbach_wikibase_2021]; SEMIC guidelines [@semic_support_centre]. On Belgian pilots: *MetaBelgica* [@meta_belgica_project] and Flemish performing arts enrichment [@magnus_podiumkunsten_2021].

The problem of scale makes such infrastructures essential. Large platforms and labels can manage millions of assets cheaply, but small actors cannot. Without shared systems, independent and community-based repertoires remain undocumented because the cost of proper registration exceeds likely revenue. Federated tools — strengthened by automation and AI — are the only realistic way to close this gap.

::: callout-note
#### Finno-Ugric Data Sharing Space

Our pilot with the **Finno-Ugric Data Sharing Space** illustrates subsidiarity in practice. By collaborating with regional NGOs and national archives, we curated and repaired datasets that would have remained invisible in a central repository. The project showed that decentralised actors are best placed to manage their own data, but that interoperability frameworks and shared observability layers can connect them effectively.
:::

International comparison confirms this. In the United States, the **Mechanical Licensing Collective (MLC)** was created in 2021 to administer a blanket mechanical license for streaming and downloads. It inherited more than \$424 million in unmatched royalties and developed large-scale reconciliation systems to allocate them. By 2022, it had already distributed nearly \$700 million. The MLC shows what can be achieved when identifiers such as ISWC and ISRC are used systematically and backed by law. But it also highlights the limits of centralisation: creators must still claim and maintain their records, education gaps persist, and disputes between platforms and rights bodies continue.[^observatory-12]

[^observatory-12]: On the MLC’s establishment and operations: [@mlc_annual_report_2021]; on contested governance and disputes with platforms: [@varghese_blackbox_2024].

::: callout-note
#### The U.S. Mechanical Licensing Collective (MLC)

The *Mechanical Licensing Collective* was created under the U.S. *Music Modernization Act* (2018) to administer a blanket mechanical license for streaming and downloads. It inherited more than \$424 million in unmatched royalties from digital services and developed large-scale reconciliation systems to allocate them. By late 2022, it had distributed nearly \$700 million.

The MLC shows what can be achieved when identifiers (ISWC, ISRC) are captured systematically and backed by legislation. But it also highlights the limits of centralisation: creators must still claim and maintain their records, education gaps persist, and disputes between platforms and rights bodies continue. For Europe, the lesson is clear: scaling metadata infrastructure is possible, but it must respect subsidiarity and federation rather than rely on a single central clearinghouse [@mlc_annual_report_2021; @varghese_blackbox_2024].
:::

### Economies of scale in metadata {#sec-economies-of-scale}

Large platforms and major labels can document millions of tracks at very low per-unit cost, because they manage everything in bulk. Smaller actors — independent labels, non-profits, or community archives — face the opposite situation: the cost of registering and maintaining each track is often higher than the revenue it will ever generate. This imbalance explains why so many “frozen” assets remain unregistered and invisible in today’s digital ecosystem.

Without a way to share infrastructure, small actors remain stuck. They cannot afford the per-track cost of full documentation, yet under-documentation ensures their work remains undiscovered. This is not just an accounting issue, but a **structural barrier to diversity** in music data flows. A federated approach, as outlined in @sec-dss-solution, is essential to rebalance these inequalities and enable small actors to benefit from the same efficiencies as global players.[^observatory-13]

[^observatory-13]: Comparative research shows that costs per asset decrease sharply with catalogue size, creating scale advantages for majors and global platforms. Without shared infrastructures, small actors are disproportionately disadvantaged. The *Feasibility Study for a European Music Observatory* emphasised this imbalance as a structural barrier [@emo_feasibility_2020, p9], while the *Music Ecosystem 2025* study highlighted how fragmentation and duplication reinforce these scale inequalities [@music_ecossytem_2025].

## Policy Proposals {#sec-observatory-proposals}

::: callout-warning
### Editing reminder {.unnumbered}

- Open Music Observatory as the convening + conformance + observability layer (not a single database).  
- Workflow playbooks: rights→distribution→charting→preservation; change-propagation patterns; provenance trails that survive system boundaries.  
- Legal/standards/public investment inline: GDPR legal bases per flow; recommended codes of conduct; lightweight policy for data fitness/quality; funding hooks (ECCCH pilots, national ministries).  
:::

::: callout-note
#### Public–private reconciliation in practice
**Reconciling public and private infrastructures: The ALOADED pilot in Latvia**

The Unlabel workflow was tested with Latvian archives and the distributor **ALOADED**, showing how public heritage metadata can be reconciled with private supply chains.  

- Archival recordings (Hilda Griva’s songs and Latvian/Latgalian midsummer songs) were located in the **Latvian Archives of Folklore**.  
- Metadata was translated, enriched, and aligned with international authority files.  
- ALOADED extended this metadata with **DDEX-compliant catalogue transfer** and ingested it into Spotify and other platforms.  

This demonstrated that reconciliation between **public infrastructures (archives)** and **private infrastructures (distributors and platforms)** is both technically and institutionally feasible, reconnecting suppressed or marginalised repertoires with contemporary audiences.
:::

Conformance and observability rules in the *Open Music Observatory* should be designed in line with the *European Interoperability Framework* (EIF) and the FAIR data principles. This ensures compatibility with wider European data space initiatives and reduces integration costs for institutions already adapting to these standards [@emo_feasibility_2020, p9].

[![The Open Music Observatory sits where open science, public sector information reuse, and music industry workflows overlap. By aligning with the European Interoperability Framework, it creates a shared space where libraries, rights managers, publishers, and researchers can collaborate. This positioning highlights OMO’s role as a bridge between cultural heritage, commercial distribution, and open knowledge. DOI: \[10.6084/m9.figshare.30073267.v1\](10.6084/m9.figshare.30073267.v1)](png/OMO/OMO_Venn_diagram.png){fig-align="center"}](https://figshare.com/articles/dataset/The_Open_Music_Observatory_at_the_Intersection_of_Open_Science_Open_Data_and_Music_Industry_Workflows/30073267?file=57754399)

### Workflow playbooks and provenance trails

The Observatory should not only harmonise data *formats* but also document **workflow playbooks** that capture how metadata flows across the music lifecycle:  
- from rights registration,  
- to distribution and royalty attribution,  
- to charting and visibility,  
- to long-term preservation.  

Each step should include **change-propagation rules**: if a correction is made in one register, it should ripple through to others. Provenance trails must survive system boundaries, using standards such as PROV-O to show *who did what, when, and under what authority*. This makes corrections auditable, supports cross-border comparability, and prevents “data death” when an asset leaves its original system.

### Federated infrastructure as a cost and governance solution {#sec-dss-solution}

The imbalance described in @sec-economies-of-scale makes one thing clear: small actors cannot compete on metadata without shared infrastructures. Federation, not centralisation, is the only viable way forward.

A **data sharing space** provides the framework. Instead of forcing everyone into a single metadata schema or legal agreement, it allows organisations to share and reuse data on an *“as-needed”* or *“as-permitted”* basis, while keeping full control of their own assets. For music — where rights, identifiers, and content are dispersed across hundreds of micro-actors and institutions — this model avoids both duplication and dependency.

Music also stress-tests the concept. Attribution rules are entangled with privacy law, identifiers are inconsistently applied, and most enterprises are too small to build compliance systems. If federation can work here, it can work anywhere. This is why the **European Music Observatory cannot be conceived as a central database**. It must function as a convening and observability layer, one that lets decentralised contributions operate as a coherent whole. In this way, the Observatory can reduce duplication, lower per-unit costs for small actors, ensure attribution, and provide the governance substrate for trustworthy AI in the music ecosystem.

Europe already has the building blocks. The **European Strategy for Data**, the **Data Governance Act**, and the **Data Act** define data spaces as federated by design, supported by trust frameworks, rulebooks, and shared services.[^observatory-14] The **Data Spaces Support Centre (DSSC)** has codified these into blueprints that can be directly applied to music.[^observatory-15] Other sectors show how this works in practice: the ISRC system distributes allocation among national agencies, CISAC’s *CIS-Net* provides rights data without centralising ownership, and statistical offices harmonise indicators through subsidiarity rather than centralisation. Music can and should build on these lessons.

[^observatory-14]: The *European Strategy for Data* (2020) defines Common European Data Spaces as federated ecosystems, while the *Data Governance Act* (2022) and *Data Act* (2023) supply the governance and access rules [@european_data_strategy_2020; @regulation_dga_2022_868].

[^observatory-15]: The *Data Spaces Support Centre (DSSC)*, led by KU Leuven with GAIA-X and BDVA, provides practical blueprints and building blocks for implementing federated data spaces in any domain [@dssc_blueprint_intro_2025; @dssc_blueprint_interop_2025].

In practical terms, this means applying *capture once, reuse many* pipelines across the entire music lifecycle: from registration of works and recordings, through distribution and royalty attribution, to preservation and cultural statistics. To achieve this, the Observatory must be designed as a **redundancy-free registration space**, aligned with the **European Interoperability Framework** and provenance-oriented models such as **PROV-O**.[^observatory-16]

[^observatory-16]: The EIF ensures interoperability across legal, organisational, semantic, and technical layers [@eif_2017]. The W3C’s PROV model and PROV-O ontology offer a standard way to connect actors, activities, and entities in chains of attribution [@prov_model_2013; @prov_o_2013]. Applied together, they enable consistent tracking of economic and cultural flows without centralising databases.

Done well, this would rebalance the playing field: lowering costs for small actors, making datasets interoperable across institutions, and ensuring that Europe’s cultural and economic policies rest on reliable evidence rather than fragmented silos.

### Legal, standards, and funding levers

For these proposals to succeed, they must be backed by **legal clarity, lightweight standards, and public investment**:  

- **Legal:** GDPR legal bases should be specified for each data flow (legitimate interest for attribution; research and cultural heritage exemptions for archives).  
- **Standards:** Codes of conduct and minimum profiles should keep conformance achievable even for micro-enterprises.  
- **Funding:** ECCCH pilots, national ministries, and EU programmes should explicitly support metadata fitness and data-quality improvements as public-interest infrastructure.  

Embedding these levers ensures that interoperability does not remain voluntary but becomes a supported and sustainable practice across Europe.

### Alignment with the European Open Science Cloud

**Bridge cultural clouds and market workflows via a federated Music Data Sharing Space.**  
Position the Open Music Observatory as the *convening + conformance + observability* layer that connects ECCCH/Europeana and GLAM authority files with industry pipelines. Concretely:  
1. **Capture once, reuse many** across creation→registration→distribution→preservation.  
2. Require **minimal profiles** that smaller actors can actually implement.  
3. Prioritise **identifier crosswalks** (ISRC↔ISWC↔ISNI↔VIAF/Wikidata) and change-propagation.  
4. Use **Wikibase/Wikidata** as a low-friction backbone where appropriate.  
5. Govern with EIF/FAIR-aligned rules, auditability, and PPP participation so rights-holders and memory institutions keep stewardship while interoperating.

This reframes Europe’s investments from siloed repositories into a shared **data space** that lowers reconciliation costs, respects subsidiarity, and makes cultural metadata usable across public and commercial contexts — the practical foundation for any future European Music Observatory.

{{< pagebreak >}}
