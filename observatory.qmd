# Open Music Observatory: Building a Shared Music Data Space {#sec-observatory}

::: callout-note
#### Open Music Observatory {.unnumbered}

Our ambition with the development of the **Open Music Observatory** is to provide the technological basis and a practical roadmap for creating a European Music Observatory in a bottom-up, decentralised way. Instead of waiting for a grand, central agreement, any data owners or collectors who satisfy quality and cooperation rules can add their data. Once the Observatory reaches sufficient maturity, its long-term institutional form can be decided.

The Open Music Observatory is a cornerstone task of the OpenMusE project (running until 31 December 2025), delivering data collection, processing, dissemination, and innovative services. It is a digital service provider for the music industry, aligned with the *European Interoperability Framework*, and introduces a unique governance model that adapts best practices from the EU and other sectors.

**Transparency note:** Following the principles of **Open Policy Analysis**, we have made all key deliverables (including versions 0.99, 1.01, and 1.1 of the *Open Music Observatory* document) publicly accessible to foster broad stakeholder engagement and to provide a clear audit trail. These versions are available at <https://zenodo.org/records/11564114>, while version 1.0 remains internal and was shared only with OpenMusE evaluators. Minor edits, as well as access to the standardised folders, figures, and bibliographies, can be found at <https://github.com/dataobservatory-eu/open-music-observatory>.

**Citation note:** If you refer to the specification of the *Open Music Observatory* in correspondence, publications, or blog posts, please cite the latest **versioned DOI** available on Zenodo and, if applicable, include the date of access when referring to material on our GitHub repository.[^observatory-1]
:::

[^observatory-1]: Always use the latest versioned DOI when citing this *Open Music Observatory* technical report, available via Zenodo. If you rely on supporting material hosted in the GitHub repository, please add the date of access in your reference.

## Executive summary

::: callout-caution
**This will be finalised after consultation**

-   Build a federated data sharing space that lets rights orgs, distributors, platforms, libraries/archives share *just enough* metadata with clear roles, auditability, and lifecycle continuity.

-   Use simple, modular agreements and conformance tests rather than a heavy centralised repository.
:::

The Music Ecosystem 2025 report already emphasised that the music sector should be understood as a distributed ecosystem where value and knowledge are held by many small actors [@music_ecossytem_2025, pp6–7]. This perspective reinforces why centralised repositories fail and why federated observatories, built on cooperation and interoperability, are more realistic.

[![Over the past decade, feasibility studies, national reports, and EU pilot projects have laid the foundation for the Open Music Observatory. The roadmap (2014–2026) shows a gradual build-up: from local experiments, through cross-border collaborations, to a European-wide federation aligned with cultural data spaces and interoperability frameworks. This trajectory underlines the Observatory’s pragmatic, step-by-step approach to scaling music data infrastructure. DOI: \[10.6084/m9.figshare.30073291.v1\](https://doi.org/10.6084/m9.figshare.30073291.v1)](png/OMO/OMO_timeline_20250908.png){fig-align="center"}](https://figshare.com/articles/figure/Timeline_of_the_Open_Music_Observatory_and_European_Music_Data_Initiatives_2014_2026_/30073291/1?file=57754420)

## Discussion

::: callout-caution
**This will be removed consultation** - EMO feasibility on scarcity/fragmentation and the need for regular, comparable data; EU dataspace thinking (EIF, FAIR); *Music Ecosystem 2025* on systemic view. - Industry positions on centralisation vs. federation; CMOs’ reliance on shared infra (e.g., Mint); heritage sector’s openness requirements.
:::

### Why centralisation is a futile model

Calls for a *centralised European database* of music often reappear in policy debates, but in practice such proposals are neither realistic nor aligned with current EU strategies. Centralisation assumes that highly diverse data sources can be harmonised within a single repository. In an ecosystem where knowledge is held by tens of thousands of micro-enterprises, NGOs, collective management organisations, and heritage institutions — each operating under distinct legal frameworks — this assumption is untenable.

EU infrastructure initiatives have already moved beyond this logic. Since the 2000s, projects such as *Europeana*, the *European Open Science Cloud (EOSC)*, the *European Collaborative Cloud for Cultural Heritage (ECCCH)*, and *DARIAH* have all adopted **federated architectures**, linking distributed collections through shared standards, profiles, and interoperability frameworks rather than consolidating them into one database. The *Audiovisual Observatory*, established in 1993 as a centralised reporting body, represents an earlier institutional logic that is now being phased out in favour of federation.

The heritage sector, including music heritage, has consistently stressed the need for *open, federated models*. Libraries, archives, and museums have adopted authority files (e.g. VIAF) and collaborative platforms (e.g. *Wikidata* and Wikibase) to enable interoperability while preserving institutional autonomy [@bianchini_beyond_2021, p210; @sardo_wikidata_2022, p297]. The emphasis here is not only on efficiency, but also on *openness* and the ability to reuse metadata across cultural domains without restrictive licensing.

The two most important industry bodies supporting the commercial circulation of hundreds of millions of music assets, CISAC and IFPI, already operate on principles of federalisation. The ISRC system, managed by IFPI as the International Registration Authority, is inherently decentralised: 58 national agencies allocate prefixes, and codes are assigned by rights owners or their representatives [@isrc_handbook_2021, p5]. This model resembles ISBN for books or ISMN for sheet music: globally unique identifiers achieved through subsidiarity and distributed governance.

CISAC operates *CIS-Net*, a federated database of works and rights information maintained by its national member societies. Although users access CIS-Net through a centralised interface, the underlying data remains under the stewardship of each member. Likewise, the Mint initiative, launched by CISAC and Armonia Online, shows how shared infrastructure can deliver economies of scale for identifier allocation and metadata management, while avoiding dependence on a single global repository [@cisac_mint_digital_services].

These federated arrangements are not temporary fixes but structural features of global identifier systems. The ISRC system functions only because allocation is distributed among national agencies [@isrc_handbook_2021, p5], while CISAC’s CIS-Net provides access to rights data without centralising ownership [@cisac_mint_digital_services]. The Observatory builds on this same principle: decentralised stewardship combined with shared interfaces and conformance rules.

Even official governmental statistics, thought to be highly centralised, have always relied on decentralised structures, particularly in the field of culture. The **ESSnet-Culture** project, coordinated under Eurostat, produced the first comprehensive framework for cultural statistics in 2012. Its final report is described as a *“basic reference”* for European culture statistics, elaborated by thematic task forces across Member States and grounded in both EU and **national data sources** [@emo_feasibility_2020, p9]. The framework, adapted from the UNESCO model, spans ten domains (heritage, archives, libraries, performing arts, etc.) and six functions (creation, trade, preservation, etc.), demonstrating that official cultural indicators are constructed through *distributed cooperation among national agencies*.

This decentralised model is not an exception but a structural feature of European statistics. National statistical offices, labour force surveys, and administrative registers each collect partial data, which are subsequently harmonised at EU level for comparability. Public policy indicators are thus inherently the result of federated cooperation, rather than centralised data lakes. Recent research extends this point further. In the age of abundant data, cultural and creative indicators increasingly rely on the *reuse of private-sector information*. Surveys and administrative datasets are being complemented by data flows from platforms, rights management organisations, and other industry actors. By extending statistical practice into these domains, European statistics are entering a new phase where privately held datasets become part of official evidence frameworks, building on earlier decentralisation while adding new layers of governance and interoperability. This represents an increasing decentralisation of evidence creation, where official statistics and policy indicators emerge from hybrid constellations of public and private data sources[^observatory-2].

[^observatory-2]: We discussed the possibility of creation music statistics in a public-private cooperation in [@antal_slovak-cult-stat-pilot].

This decentralised model is not an exception but a structural feature of European statistics. National statistical offices, labour force surveys, and administrative registers each collect partial data, which are subsequently harmonised at EU level for comparability. Public policy indicators are thus inherently the result of federated cooperation, rather than centralised data lakes.

This trajectory mirrors the broader evolution of European data infrastructures, where federation has become the dominant organising principle. The Music Ecosystem 2025 study framed the music sector as an ecosystem distributed across many small actors [@music_ecossytem_2025, pp6–7], while the Feasibility Study for a European Music Observatory highlighted fragmentation as the primary obstacle to evidence-based policy [@emo_feasibility_2020, p9]. Both perspectives underline why federated architectures are more feasible than centralised repositories.

### Open Data Directive: Right Without Means

The *Open Data Directive* grants a right of reuse for public-sector information and requires that certain “high-value datasets” be made freely available across Europe [@directive_open_data_2019]. This includes cultural heritage institutions such as libraries, museums, and archives. However, the Directive stops short of providing the means to ensure that such data is actually usable.

Studies consistently show that open data remains more of a promise than a reality [^observatory-3]. In practice, much open data is poorly documented, lacks common identifiers, and is released in unstandardised formats. While it may be free of charge or available at marginal cost, making it interoperable and trustworthy for cross-border use requires significant additional effort. The burden of curation, harmonisation, and enrichment falls on downstream users, which can be prohibitively expensive for smaller organisations. As the CEDAR project put it, *“Public authorities are only required to make existing data available, not to create new data or improve existing systems. This leads to significant disparities in usability and accessibility”* [@cedar_hvd_2023]. A recent EU-wide usability study adds that *“many open data portals remain difficult to navigate, poorly documented, and inconsistent in their metadata quality, limiting actual reuse”* [@jachimczyk_open_data_usability_2024].

[^observatory-3]: Early analyses underlined that *“the economic potential of open data is significant, but realising this potential depends on overcoming barriers to data availability, quality and usability”* [@carrara_creating_2015, p.7]. Later modelling confirmed the vast estimated value of open data, but stressed that *“in practice, the impact of open data depends heavily on the extent to which it is discoverable, accessible, and usable”* [@huyer_economic_2020, p.14]. This has direct consequences for domains with complex metadata like music, where rights and attribution depend on accurate, standardised, and machine-readable records. Empirical studies across sectors show why legal openness alone rarely yields machine-actionable reuse. This is not only a music-specific problem, though the need for high-quality, standardised data in music is unusually high. Analyses of EU public-sector openness find that, absent prescriptive technical mandates, agencies publish heterogeneous formats and divergent practices, which fragment reuse across countries and sectors [@buttow_meijer_openness_2024, p.12]. Regional benchmarking of high-value geospatial data similarly reports variability in machine-readable provision and metadata completeness, with practical usability suffering even where datasets exist [@kevic_godi_plus_2023, p.3]. Cross-holder case studies (e.g., mineral intelligence) continue to call for harmonised structures and output formats, underscoring the need for shared profiles beyond the baseline legal right to reuse [@simoni_mintell4eu_2021, p.5]. Beyond formats, evidence shows that preparing legacy administrative data for actual reuse (cleansing, standardising, describing) imposes non-trivial costs on data holders and re-users—zero price does not eliminate acquisition, transformation, and integration costs [@eurosdr_nmcabiz_2021, p.9; @schnurr_ogd_markets_2021, p.14; @nakos_nautical_2022, p.6].

This gap is directly relevant to the music ecosystem. Simply publishing datasets under the Open Data Directive does not make them fit for royalty distribution, cultural statistics, or AI-driven discovery. The Open Music Observatory seeks to fill this gap by turning “open data in principle” into **reusable data in practice**, through shared identifiers, metadata profiles, and federation rules.

### Why Voluntary Workarounds Do Not Scale {#sec-gdpr-observatory}

The Slovak pilot shows that voluntary workarounds for attribution under GDPR are possible (see @sec-gdpr-curation), but they do not scale. Even with strong communication and opt-in procedures, fewer than 1.3% of authors responded. Every new dataset requires fresh balancing tests, repeated notifications, and continued exposure to legal risk.

For observatories and data spaces, this is untenable. Interoperability requires clarity and legal certainty across borders and institutions. Without guidance from a Data Protection Authority or the European Commission, every national or sectoral initiative risks being challenged. The consequence is paralysis: public infrastructures cannot fully attribute works, and private actors refrain from sharing metadata for fear of liability.

In effect, Europe’s music data infrastructures remain locked in uncertainty — unable to guarantee attribution, diversity monitoring, or local content compliance. This makes a purely local or voluntary approach insufficient. The solution must be systemic: a **federated data sharing space**, supported by common specifications and clear governance frameworks, so that attribution and interoperability can scale. These unresolved attribution issues ultimately undermine not only observatories but also AI fairness and governance (see @sec-gdpr-ai).



### Public cultural infrastructures bypass music’s real data flows

Europe has invested heavily in Europeana, ECCCH and other cultural data infrastructures, but their data models and workflows remain weakly aligned with how music metadata is generated and maintained in practice — largely by private actors (labels, distributors, CMOs) who already finished most digitisation, including heritage repertoire. Unlike in the case of old libraries, documentary records in archives, artefacts in museums, where digitisation is mainly funded with public money, in music and film most of the digitisation took place (also for high-value classical, early or folk music) in the private sector.

The *Europeana Data Model* was based mainly on public collection practices and library models, and it cannot truly handle the fact that music that can be listened to and viewed has at least three creator groups that need to be assigned: authors, producers and performers. We have been proposing solutions for this to Europeana, and we hope that during the remaining period of OpenMusE we will be able to demonstrate our solution (see later.) [^observatory-4]

[^observatory-4]: The Europeana data model largely builds on DCTERMS, which is suitable for handling printed music sheets; they are regularly stored in library systems. Printed music needs a reference for the author and the publisher. However, sound recordings (including video sound recordings) must identify the neighboring rightsholders, the producer and the performer. See our suggestions later in this chapter. [@EDM_2017]

The *Report on a European collaborative cloud for cultural heritage* (ECCCH report) does not mention music at all. Its scope was conceived around heritage institutions (archives, museums, libraries, monuments), and it overlooked the specific needs of the music sector.[^observatory-5] The first ECCCH projects focus on digitisation and advanced data infrastructures for cultural heritage, but none address music directly. **AUTOMATA** develops low-cost, AI-assisted digitisation workflows for archaeological ceramics and lithics, integrating enriched 3D data into the cloud. **TEXTaiLES** tackles the specific challenges of textile heritage, creating AI- and sensor-based tools for capturing, preserving, and restoring fabrics. **HERITALISE** advances digitisation across diverse heritage assets, using machine learning, CT scanning, HBIM, and XR/VR services for immersive representation and conservation. **ECHOES** establishes the core European Cultural Heritage Cloud, building a shared platform with interoperable tools, metadata vocabularies, and training for heritage professionals. We tried to establish contact with ECHOES, and we also suggested in their cascading grant program to fit in large music datasets that handle all aspects of music metadata; one of them was eliminated in the first stage, the other, related to a conceptual exploitation pathway of our Open Music Observatory, the Finno-Ugric Data Sharing Space, may still be able to try to insert music data into the ECCCH.

[^observatory-5]: *Report on a European collaborative cloud for cultural heritage – Ex–ante impact assessment* [@eccch_report_2022]

Even the **Polifonia project**, which we cited earlier as a good example and whose methodology we could use well, was "blind" to the private data infrastructure of music. While it created a set of modular ontologies, it did not cover rights management, and even its central classes for musical works and sound recordings were not fully aligned with the ISWC and ISRC standards used by industry to identify and register musical works and sound recordings.

This misalignment is structural, not incidental. The result is duplication and gaps: public knowledge graphs and registries don’t interoperate smoothly with industry identifiers (ISRC/ISWC/ISNI/IPN), reconciliation is costly, and culturally significant catalogues stay under-used across public and commercial systems. This is a missed opportunity for both sectors.

### Alignment with the European Open Science Cloud (EOSC)

The **European Open Science Cloud (EOSC)** is intended as Europe’s flagship infrastructure for sharing and reusing research data across domains. By “EOSC data model” we mean the conceptual and technical framework that enables EOSC to function as a federated, distributed, and interoperable ecosystem for research data, tools, and services.

In practice, EOSC remains highly complex and fragmented, and its connections to music are limited. Music has been touched only tangentially, mainly through the work of **DARIAH-EU** (*Digital Research Infrastructure for the Arts and Humanities*), which has supported humanities-driven approaches to digital musicology but not the broader music ecosystem. Yet, just like in ECCCH, we see music underrepresented in the DARIAH-EU system.

In our understanding, the **ECHOES** project aims to build interoperability with cultural data providers as well as EOSC.

Our projects already interact with EOSC through **Zenodo** and **OpenAIRE**. We deposit music-related datasets on Zenodo, ensuring visibility, persistence (via DOIs), and EOSC integration. This creates a foothold for music data within EOSC, and we see that some of our deposits are highly visited. However, so far we do not see a clear curatorial pathway for music-related research being deposited in large quantities to EOSC, or industry being able to easily utilise music data from EOSC.

From a policy perspective, EOSC should not be overlooked: it is the default European infrastructure for open science, and cultural heritage and creative industry data are increasingly expected to align with it. For music, this means recognising where EOSC provides real value — long-term preservation, persistent identifiers, cross-domain discovery — while also acknowledging its gaps in rights-aware, industry-aligned metadata. Our strategy is to use EOSC as a **public backbone for open deposits**, while federating more specialised infrastructures (such as the Open Music Observatory) to ensure that music’s specific needs for identifiers, attribution, and rights management are respected.

### European Interoperability Framework

The **European Interoperability Framework (EIF)** is the European Commission’s reference model for building interoperable digital public services across Member States. It defines interoperability not only in technical terms, but also across legal, organisational, and semantic layers, ensuring that administrations can exchange data and services smoothly while respecting national sovereignty.

Although the EIF formally applies to public administrations, its layered approach is highly relevant for the music ecosystem. Cultural data and rights metadata circulate between public institutions (such as libraries, archives, or ministries), private actors (platforms, CMOs, publishers), and hybrid organisations (NGOs, research infrastructures). By adopting the EIF’s multi-layered model, the Open Music Observatory ensures that federation is not limited to technical standards but also extends to governance, semantics, and legal compliance.

The European Commission’s *European Strategy for Data* already frames interoperability as a cornerstone of Common European Data Spaces, which are to be built as **federated infrastructures** underpinned by European laws and standards [@european_data_strategy_2020]. BDVA and DAIRO echo this point, emphasising that interoperability frameworks such as the EIF are necessary to operationalise federation in practice [@bdva_discussion_paper_2023, p.18; @federation_wg_position_2023, p.4]. For participants in the music ecosystem, this means lower integration costs and greater predictability: institutions already adapting to EIF-based rules in research or e-government can reuse those frameworks in the Observatory.

### Subsidiarity in Platform Design

The European principle of subsidiarity requires that decisions be taken as closely as possible to the citizens they affect. In cultural policy, this translates into responsibilities distributed across multiple levels: in some Member States, culture is managed regionally or provincially; in others, at the national level. This creates a patchwork where data about music and cultural heritage is controlled by different authorities, depending on the administrative tradition of each country.

This diversity extends beyond public administrations. Many important datasets are held by private actors, including collective management organisations, commercial platforms, and non-profit archives. As a result, any attempt to centralise music data governance would risk losing both legitimacy and local relevance.

Designing the Observatory around subsidiarity means recognising these structural differences and embedding them into its architecture. The EIF helps here by providing a layered model for reconciling data governance (permissions, licences) at the legal level and organisational rules at the institutional level. This ensures that local, regional, national, and private actors can contribute data under their own governance, while outputs remain reusable across Europe.

The **Data Governance Act (DGA)** reinforces this approach. It establishes EU-wide rules for trusted data sharing and data intermediation services while leaving implementation and control at the Member State level [@regulation_dga_2022_868]. In other words, it codifies subsidiarity: national authorities retain stewardship over sensitive datasets, but EU-level standards guarantee that these datasets can circulate securely and comparably across borders. The Observatory applies this same principle to music: rights organisations, archives, and platforms remain in charge of their data, while interoperability, accountability, and observability are ensured through a shared European layer.

The European Data Strategy explicitly recognises subsidiarity by promoting data spaces that respect *sectoral and national diversity while enabling interoperability across borders* [@european_data_strategy_2020]. The BDVA Federation Working Group goes further, arguing that federation is the only model compatible with Europe’s fragmented governance landscape [@federation_wg_position_2023, p.4]. The Observatory takes these insights into account by embedding subsidiarity into its platform design: respecting local authority, while enabling European-scale reuse.

::: callout-note
Our pilot with the Finno-Ugric Data Sharing Space illustrates how subsidiarity works in practice. By collaborating with regional NGOs and national archives, we were able to curate and repair datasets that would have remained invisible in a central repository. The project showed that decentralised actors are best placed to manage their own data, but that interoperability frameworks and shared observability layers can connect them effectively.
:::

### Economies of Scale in Metadata

Large platforms and major labels manage to document millions of assets in parallel, achieving economies of scale that smaller actors cannot match. By contrast, for SMEs, non-profits, or community archives, the cost of documentation per asset is disproportionately high, often exceeding the commercial value of the repertoire. This gap explains why so many “frozen” assets remain unregistered and invisible in the digital ecosystem.

Agentic AI, if deployed within a shared knowledge base and aligned with modular ontologies in a federated data sharing space, can reduce operational expenditure (OPEX) by automating repetitive documentation tasks. This would allow smaller players to benefit from the same scale effects as the global platforms, without compromising quality or compliance. The frozen asset case is only the most visible example: AI-enabled economies of scale would lower costs across the entire long tail of music assets.

### The U.S. Mechanical Licensing Collective (MLC) as a Metadata Clearinghouse

The *Mechanical Licensing Collective* (MLC) was created under the U.S. *Music Modernization Act* (2018) and began operations in January 2021. It administers a **blanket mechanical license** for digital streaming and download services, replacing fragmented song-by-song licensing. Its mandate is to ensure that songwriters, lyricists, composers, and publishers receive timely mechanical royalties, while providing transparency through a public works database and member portal [@mlc_annual_report_2021].

From its inception, the MLC inherited more than **\$424 million in unmatched royalties** from digital service providers (DSPs)—funds that could not be allocated because works were not properly registered or matched. These unmatched sums must eventually be distributed, and if they cannot be claimed, they are paid out to publishers on a market-share basis. For independent songwriters, this creates both an opportunity and a risk: registration with the MLC is free, but failure to register means royalties may be permanently lost.

The MLC highlights a systemic lesson: identifiers like ISWC and ISRC must be correctly captured and maintained at source, or royalties remain trapped in the “black box.” To address this, the MLC has developed **matching and reconciliation routines** and offers search tools so creators can check whether their works are properly registered. Education remains a critical challenge, since many independent songwriters incorrectly assume that affiliation with ASCAP, BMI, or SESAC (performance rights organisations) covers mechanical royalties as well.

By late 2022, the MLC had already distributed nearly **\$700 million in royalties**, but its operations also illustrate the fragility of metadata-dependent systems. In 2025, it filed—and lost—a high-profile lawsuit against Spotify, which had sought to classify audiobooks within its music service to reduce royalty obligations [@varghese_blackbox_2024]. This underscores that even with centralised licensing, **governance and enforcement remain contested**.

For European debates, the MLC demonstrates how a large-scale, rights-compliant clearinghouse can consolidate reporting, improve metadata quality, and distribute royalties more transparently. Yet it also shows the **limits of centralisation**: creators still need to actively claim and maintain their records, education gaps persist, and disputes between collective agencies and global platforms remain unresolved.

### Data Sharing Space

A **data sharing space** is both a governance framework and a technical architecture that allows independent organisations to share, access, and reuse data under agreed rules, without relinquishing control over their assets. Instead of pooling everything into a central repository, each participant maintains stewardship of its own datasets while aligning with interoperability profiles, identifier schemes, and contractual safeguards. This arrangement lowers duplication costs, strengthens legal certainty, and builds trust among actors with diverse incentives but overlapping needs. In practice, data sharing spaces operate through a common semantic and governance layer — for example, shared identifier systems, metadata crosswalks, and access policies — while leaving local databases and workflows intact.

The European Commission’s communication *A European Strategy for Data* defines *Common European Data Spaces* as **federated infrastructures**, designed to enable secure and accountable data flows across Member States and sectors, underpinned by European laws, standards, and governance frameworks [@european_data_strategy_2020]. Industry and research communities reinforce this interpretation. The BDVA/DAIRO discussion paper specifies that data spaces are *“federated data ecosystems within a certain application domain and based on shared policies and rules”* [@bdva_discussion_paper_2023, p.18], while the Federation Working Group stresses that federation is the key enabler of cross-sector interoperability in Europe [@federation_wg_position_2023, p.4]. This convergence of policy and practice underscores why federation — not centralisation — is the preferred model for future observatories.

For the music ecosystem, a data sharing space provides three immediate benefits. First, it reduces reconciliation costs by promoting *“capture once, reuse many”* practices: identifiers and metadata entered in one system can propagate to others. Second, it safeguards subsidiarity by ensuring that collective management organisations, archives, and platforms remain responsible for their own registries. Third, it enhances observability: policymakers, creators, and researchers can monitor flows across the sector without requiring full access to proprietary data.

The *Feasibility Study for a European Music Observatory* already recognised that fragmentation and duplication are structural features of the music sector [@emo_feasibility_2020, p9]. A federated data sharing space addresses this by acknowledging decentralisation as a fact and turning it into an advantage. Instead of aspiring to a monolithic central repository, the Open Music Observatory is conceived as a convening, conformance, and observability layer that enables decentralised contributions to function as a coherent whole.

As we mentioned in the problem discussion, our Slovak pilot shows that voluntary workarounds for attribution under GDPR are possible, but they do not scale. 

Partial solutions exist. The **Data Space Support Centre (DSSC)** led by KU Leuven, in collaboration with GAIA-X and BDVA, has developed blueprints and building blocks to scale data sharing under current legal frameworks. These mechanisms can help stabilise the “tinkering” approach and provide a technical foundation for federated governance.  

But the real solution cannot come from technical fixes alone. The **European Parliament’s resolution on music streaming** clearly calls for systematic identifier usage and stronger attribution. Meeting this goal requires action from the Commission: either by clarifying GDPR for attribution data, requesting guidance from DPAs, or ultimately pursuing a legislative or jurisprudential solution. Only then can data spaces for music scale legally and sustainably across Europe.


### Wikibase as a Cultural Metadata Backbone

Wikibase, the software underpinning *Wikidata*, has become a proven solution for collaborative metadata management. Originally developed by Wikimedia Deutschland, it is now widely used in cultural heritage contexts, including libraries, museums, and music-related projects. Studies highlight that Wikibase provides both a **flexible but structured data model** and an **accessible user interface**, making it suitable for non-expert users to maintain knowledge graphs and produce CIDOC-CRM compliant RDF [@kesaniemi_wb_cidoc_2022, p542].

Comparative analyses show that Wikidata, powered by Wikibase, is already functioning as a **complementary tool for authority control**, alongside traditional infrastructures like VIAF, enabling interoperability across bibliographic and heritage domains [@bianchini_beyond_2021, p210; @sardo_wikidata_2022, p297]. Other work had already emphasised its role six years ago as an emerging authority hub, where Wikidata identifiers can act as universal references, lowering barriers to linked open data integration [@van_veen_wikidata_2019, p75].

Within the European Union itself, Wikibase has been adopted as the infrastructure behind the **EU Knowledge Graph**, used by the European Commission to integrate projects funded under EU programmes and make them accessible to citizens [@diefenbach_wikibase_2021]. The *SEMIC 2020 initiative* also highlighted Wikibase and Wikidata as sustainable data services for public-sector interoperability [@semic_2020_providing_2020], while recent work demonstrates their potential as research data management services in the cultural heritage field [@rossenova_wikidata_2022].

Within Europe’s public-sector linked-data ecosystem, **SEMIC** has identified *Wikidata* and Wikibase as the primary tools to enable collaborative semantic modeling and ensure interoperability among public data spaces [@semic_support_centre]. At the Belgian national level, the *MetaBelgica* project—a collaboration among federal scientific heritage institutions—explicitly uses Wikibase to host FAIR-compliant entity data and to support long-term, multi-institutional curation workflows [@meta_belgica_project, p1]. This demonstrates Wikibase’s viability as an infrastructure component for federated metadata systems in Europe, and makes its adoption in the Flemish OSLO-linked framework (e.g., for *cultuurparticipatie* via the Uitwisselingsplatform) both plausible and justified.

At the sectoral level, the Flemish performing arts field has already piloted such an approach. Since 2017, PACKED (now meemoo) and *Kunstenpunt* (Flanders Arts Institute) have experimented with publishing performing arts data on Wikimedia platforms. In 2021, Kunstenpunt uploaded production data from its database (since 1993) into Wikidata using Wikibase as the curation and linking environment. As Magnus and Van D’huynslager explain: *“We wanted to test how data becomes richer from the outset by publishing it as linked open data on Wikidata, and to see how much enrichment would arise later through the community”* [@magnus_podiumkunsten_2021]. The upload produced immediate enrichment: *“About 1700 of the uploaded venues have specific geo-coordinates on Wikidata … more than 2000 persons and more than 750 venues … now have a photo on Wikidata”* [@magnus_podiumkunsten_2021].

Together, these examples show that Wikibase/Wikidata is not only technically mature, but already embedded in Flemish and Belgian cultural infrastructures: from EU-level interoperability frameworks to federal scientific heritage institutions and practical performing arts pilots. This makes it a pragmatic reference point for designing federated, decentralised metadata infrastructures in the music sector.

This makes Wikibase/Wikidata a pragmatic starting point for federated metadata infrastructures: institutions can host their own Wikibase instances while linking into the global Wikidata ecosystem, ensuring decentralised control with global interoperability.

## Policy Proposals

-   Open Music Observatory as the convening + conformance + observability layer (not a single database).
-   Workflow playbooks: rights→distribution→charting→preservation; change-propagation patterns; provenance trails that survive system boundaries.
-   Legal/standards/public investment inline: GDPR legal bases per flow; recommended codes of conduct; lightweight policy for data fitness/quality; funding hooks (ECCCH pilots, national ministries).

Conformance and observability rules in the *Open Music Observatory* should be designed in line with the *European Interoperability Framework* (EIF) and the FAIR data principles. This ensures compatibility with wider European data space initiatives and reduces integration costs for institutions already adapting to these standards [@emo_feasibility_2020, p9].

[![The Open Music Observatory sits where open science, public sector information reuse, and music industry workflows overlap. By aligning with the European Interoperability Framework, it creates a shared space where libraries, rights managers, publishers, and researchers can collaborate. This positioning highlights OMO’s role as a bridge between cultural heritage, commercial distribution, and open knowledge. DOI: \[10.6084/m9.figshare.30073267.v1\](10.6084/m9.figshare.30073267.v1)](png/OMO/OMO_Venn_diagram.png){fig-align="center"}](https://figshare.com/articles/dataset/The_Open_Music_Observatory_at_the_Intersection_of_Open_Science_Open_Data_and_Music_Industry_Workflows/30073267?file=57754399)

### Federated Infrastructure as a Cost and Governance Solution {#sec-dss-solution}

As introduced in @sec-dataspace-definition, a **data sharing space** allows organisations to exchange and reuse data on an *“as-needed”* or *“as-permitted”* basis, while keeping full control of their own assets. This avoids the impossible task of forcing everyone into a single metadata schema or legal agreement in advance. For music — where rights, identifiers, and content are dispersed across hundreds of micro-actors and institutions — such federation is the only realistic option.

The challenge is that music also stress-tests the model. Attribution is entangled with privacy law, rights data are inconsistently standardised, and most enterprises are too small to build complex compliance systems. In this sense, music is both a “problem case” and a laboratory: if federation can work here, it can work anywhere.

The lesson is clear: the **European Music Observatory cannot be a central database**. It must be designed as a federated data sharing space — a convening and observability layer that enables decentralised contributions to function as a coherent whole. Only in this form can it reduce duplication, lower per-unit costs for small actors, ensure attribution, and provide the governance substrate needed for trustworthy AI in the music ecosystem.[^dss]

[^dss]: **Policy and practice foundations for data spaces in music.**  
- **EU baseline.** The *European Strategy for Data* (2020) defines Common European Data Spaces as federated ecosystems; the *Data Governance Act* (2022) and *Data Act* (2023) provide the governance tools and access rights.  
- **Technical frameworks.** The *Data Spaces Support Centre (DSSC)* in its *Blueprint v2.0* sets out participants, services, rulebooks, and cross-data space interoperability profiles [@dssc_blueprint_intro_2025; @dssc_blueprint_interop_2025].  
- **Governance framing.** The **Big Data Value Association (BDVA)** highlights trusted frameworks, lifecycle integration, and governance pillars with trust at the centre [@bdva_position_2019; @bdva_designing_2022; @bdva_discussion_paper_2023]. The **Federation Working Group** identifies federation, not centralisation, as the only sustainable model [@federation_wg_position_2023].  
- **Music mandate.** The *Feasibility Study for a European Music Observatory* and the *Music Ecosystem 2025* study both document fragmentation and duplication in music markets, calling for federated solutions. The **European Parliament’s Resolution on the music streaming market** reinforces this by urging systematic use of ISNI, IPI, IPN alongside ISWC/ISRC, and stronger attribution [@emo_feasibility_2020; @music_ecossytem_2025; @ep_resolution_music_streaming_2024].

### Make Open Data Truly Accessible

The gaps of the *Open Data Directive* are not unique to the music sector. Across Europe, datasets are frequently released in heterogeneous formats, with incomplete metadata, and little harmonisation between Member States. A well-designed **data sharing space** addresses these weaknesses by providing the semantic, technical, and governance building blocks that turn legal openness into practical interoperability.

The *Open Music Observatory* can take on this role in three complementary ways. First, it should provide *reference blueprints* and mappings to existing standards, ensuring that high-value datasets are consistently published in machine-readable formats rather than ad-hoc encodings [@noardo_standards_2024]. Second, it should integrate *semantic vocabularies and metadata profiles*, reducing interpretation friction across Member States and sectors [@atzori_dataspaces_2023]. Third, it should supply *shared transformation pipelines and validation tooling*, so that cleaning and integration costs are not borne by every user independently but distributed across the ecosystem [@klimek_stirdata_2023].

Equally important, data spaces embed governance rules and certification processes into their architecture: conformance tests, trust frameworks, and legal interoperability mechanisms ensure that data use is both technically reliable and legally safe [@terzis_ehds_2024]. In this way, data sharing spaces do not simply *publish* data but actively lower transaction costs, prevent fragmentation, and ensure compliance across borders.

For the music sector, a data sharing space anchored in the *Open Music Observatory* would guarantee that datasets — whether from CMOs, platforms, or cultural institutions — are published with agreed profiles, identifiers, and governance safeguards. This creates an infrastructure where decentralised actors can interoperate at scale without losing autonomy.[^observatory-6] Yet, data sharing spaces are not a silver bullet: they can prevent the creation of unusable data in the future, but legacy releases require a complementary strategy — namely the application of **curative AI**. This is the focus of the next section (@sec-ai).

[^observatory-6]: Comparative research shows that without prescriptive standards, high-value datasets are released in divergent formats and with incomplete metadata, undermining reuse [@klimek_stirdata_2023, p.184]. Reference models and blueprint components can mitigate this by aligning producers around canonical schemas [@noardo_standards_2024]. Data spaces also address semantic and legal interoperability together — shared vocabularies, certification processes, and trust frameworks reduce uncertainty and lower entry costs for SMEs and public institutions alike [@atzori_dataspaces_2023; @terzis_ehds_2024].

### Connect to Europeana & ECCCH

We are not only pointing out gaps — we are also building bridges. In 2024, we formally requested to become a **Europeana data provider**, with the intention of delivering a dataset larger than Europeana’s current music holdings. Our pilot shows that even the existing EDM can be used to expose a much richer set of music for listening and viewing, though some modernisation will be inevitable. This would demonstrate that music can be integrated into Europeana without waiting for a full re-engineering of its model.

We also submitted **two cascading grant proposals** to the ECHOES consortium, seeking to demonstrate how music metadata can flow across both public and private infrastructures. One proposal — based on Livonian folk music from the Latvian Archives of Folklore — was unsuccessful, but another, linked to our **Finno-Ugric Data Sharing Space** (a conceptual pathway of the Open Music Observatory), may still enable insertion of music data into ECCCH. Regardless of funding outcomes, we see value in dialogue between the ECHOES/ECCCH data model and the Open Music Observatory’s model.

Our choice of **Wikibase/Wikidata** as the technical backbone is deliberate. Wikidata has proven its ability to connect public and private infrastructures at global scale, and it is formally recommended by the EU Publications Office as a semantic authority. Wikibase offers a pragmatic way to map elements of public and private ontologies, enabling cooperation without forcing either side to abandon its systems. With Google among its early supporters, Wikidata is today the largest open graph in the world — an infrastructure already woven into the backbone of the web.

Our approach is one of **ontological pragmatism**: using tested, open technologies to bridge gaps, while focusing on the harder legal and organisational aspects of interoperability in a public-private setting. This makes the Open Music Observatory not just another cultural repository, but a realistic path towards aligning music’s real data flows with Europe’s wider cultural data infrastructures.

### Alignment with the European Open Science Cloud

#### Other

**Bridge cultural clouds and market workflows via a federated Music Data Sharing Space.**\
Position the Open Music Observatory as the *convening + conformance + observability* layer that connects ECCCH/Europeana and GLAM authority files with industry pipelines. Concretely: (1) **capture once, reuse many** across creation→registration→distribution→preservation; (2) require **minimal profiles** that smaller actors can actually implement; (3) prioritise **identifier crosswalks** (ISRC↔ISWC↔ISNI↔VIAF/Wikidata) and change-propagation; (4) use **Wikibase/Wikidata** as a low-friction backbone where appropriate; (5) govern with EIF/FAIR-aligned rules, auditability, and PPP participation so rights-holders and memory institutions keep stewardship while interoperating.

This reframes Europe’s investments from siloed repositories into a shared **data space** that lowers reconciliation costs, respects subsidiarity, and makes cultural metadata usable across public and commercial contexts — the practical foundation for any future European Music Observatory.

{{< pagebreak >}}
